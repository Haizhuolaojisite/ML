在监督学习时，我们经常会看到别人把数据分为training set和test set，究竟为何要这样做？

数据分割
如果你在使用同一组数据来训练模型，并且用同一组数据来测试模型的话，模型会给出一个相当完美的得分。
但是当你将模型扩展到未知数据时，效果就差强人意了。

这种情况叫做过拟合。

为了避免这种情况，我们会将数据分成两部分，一部分用来训练，叫做training set， 另一部分用来测试，叫做test set。

看起来似乎这样就可以解决问题了？

并没有。

每个模型还有一些对应的参数（hyperparameters)，当我们在测试集上调参时，我们其实不知不觉中泄露了一些测试集的信息给模型，这样还是会造成模型无法泛化。

为了解决这个问题，我们还需要一部分数据，来做validation set。

于是，整个流程变成了。

分割数据 -> training set训练 -> validation set验证 -> test set验证

但是把原有的数据分成三份，大量的减少了用于训练的数据量。这就使模型的结果过度依赖于用于训练数据。

交叉验证
Cross-validation 就是用来解决这个问题。

引入CV后，测试集仍旧用于最终的评估，但是我们不再需要validation-set。

已k-fold CV为例，训练集被分类k个小数据集，之后用一下的方式训练模型：

0. 初始化一个新模型
1. 用k-1份数据来训练模型。
2. 用剩下的那一份数据来对模型进行验证。
模型的总体表现用k次评估的平均值来表示。

这样可以在保证训练数据量的情况下来保证模型评估的准确性。

总结
在引入CV后，整个流程变为：

分割数据 -> cv训练、评估数据 -> test set最终评估
